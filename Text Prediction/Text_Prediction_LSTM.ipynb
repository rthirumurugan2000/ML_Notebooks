{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Prediction LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PjfUlRS5_PF"
      },
      "source": [
        "# Text Prediction Using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7nmD_vl57gh",
        "outputId": "64461f27-7289-4e33-c3c2-fdfa2c3bfdb4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_i-h3Zv6F2d"
      },
      "source": [
        "# Imports\n",
        "import sys\n",
        "import numpy as np\n",
        "import string, os \n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCbRUeMh8iE_"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgOPWiNU8kb5"
      },
      "source": [
        "text = '/content/gdrive/MyDrive/ti.txt'\n",
        "raw_text = open(text, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s_hx-_lIxWX"
      },
      "source": [
        "def clean_text(txt):\n",
        "    punct = ['{','}','$','%','&','#','*','/',':',';','?','@','_','[',']']\n",
        "    txt = \"\".join(v for v in txt if v not in punct).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    raw = \"\"\n",
        "    for line in txt:\n",
        "      stripped_line = line.rstrip('\\n')\n",
        "      raw += stripped_line\n",
        "    new_text = ''.join(c for c in raw if not c.isdigit())\n",
        "    return new_text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gz2l_EAI0Yt"
      },
      "source": [
        "new_text = clean_text(raw_text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "qLiFCddlI2RB",
        "outputId": "628b119e-7df3-415c-e9b3-b78370c988e6"
      },
      "source": [
        "new_text[0:8000]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the project gutenberg ebook of treasure island, by robert louis stevensonthis ebook is for the use of anyone anywhere in the united states and mostother parts of the world at no cost and with almost no restrictionswhatsoever.  you may copy it, give it away or re-use it under the terms ofthe project gutenberg license included with this ebook or online atwww.gutenberg.org.  if you are not located in the united states, you'll haveto check the laws of the country where you are located before using this ebook.title treasure islandauthor robert louis stevensonillustrator louis rheadrelease date march ,  ebook most recently updated october , language englishcharacter set encoding utf- start of this project gutenberg ebook treasure island produced by judy boss, john hamm, arthur dibianca and david widgertreasure islandby robert louis stevensontreasure islandto s.l.o., an american gentleman in accordance with whose classic tastethe following narrative has been designed, it is now, in return fornumerous delightful hours, and with the kindest wishes, dedicated by hisaffectionate friend, the author.               to the hesitating purchaser               if sailor tales to sailor tunes,                  storm and adventure, heat and cold,               if schooners, islands, and maroons,                  and buccaneers, and buried gold,               and all the old romance, retold                  exactly in the ancient way,               can please, as me they pleased of old,                  the wiser youngsters of today               --so be it, and fall on!  if not,                  if studious youth no longer crave,               his ancient appetites forgot,                  kingston, or ballantyne the brave,               or cooper of the wood and wave                  so be it, also!  and may i               and all my pirates share the grave                  where these and their creations lie!     contents     part one     the old buccaneer     .  the old sea-dog at the admiral benbow          .  black dog appears and disappears . . . .       .  the black spot . . . . . . . . . . . . .       .  the sea-chest  . . . . . . . . . . . . .       .  the last of the blind man  . . . . . . .       .  the captains papers . . . . . . . . . .       part two     the sea cook     .  i go to bristol  . . . . . . . . . . . . .      .  at the sign of the spy-glass . . . . . . .      .  powder and arms  . . . . . . . . . . . . .      .  the voyage . . . . . . . . . . . . . . .       .  what i heard in the apple barrel . . . .       .  council of war . . . . . . . . . . . . .       part three     my shore adventure     .  how my shore adventure began . . . . . .       .  the first blow . . . . . . . . . . . . .       .  the man of the island. . . . . . . . . .       part four     the stockade     .  narrative continued by the doctor            how the ship was abandoned . . . . . .      .  narrative continued by the doctor            the jolly-boats last trip . . . . . .      .  narrative continued by the doctor            end of the first days fighting  . . .      .  narrative resumed by jim hawkins            the garrison in the stockade . . . . .      .  silvers embassy . . . . . . . . . . . .      .  the attack . . . . . . . . . . . . . . .      part five     my sea adventure     .  how my sea adventure began . . . . . . .      .  the ebb-tide runs  . . . . . . . . . . .      .  the cruise of the coracle  . . . . . . .      .  i strike the jolly roger . . . . . . . .      .  israel hands . . . . . . . . . . . . . .      .  pieces of eight  . . . . . . . . . . .      part six     captain silver     .  in the enemys camp  . . . . . . . . . .      .  the black spot again . . . . . . . . . .      .  on parole  . . . . . . . . . . . . . . .      .  the treasure-hunt--flints pointer . . .      .  the treasure-hunt--the voice among            the trees  . . . . . . . . . . . . . .      .  the fall of a chieftain  . . . . . . . .      .  and last . . . . . . . . . . . . . . . . treasure islandpart one--the old buccaneerthe old sea-dog at the admiral benbowsquire trelawney, dr. livesey, and the rest of these gentlemen havingasked me to write down the whole particulars about treasure island, fromthe beginning to the end, keeping nothing back but the bearings of theisland, and that only because there is still treasure not yet lifted, itake up my pen in the year of grace  and go back to the time whenmy father kept the admiral benbow inn and the brown old seaman with thesabre cut first took up his lodging under our roof.i remember him as if it were yesterday, as he came plodding to theinn door, his sea-chest following behind him in a hand-barrow--atall, strong, heavy, nut-brown man, his tarry pigtail falling over theshoulder of his soiled blue coat, his hands ragged and scarred, withblack, broken nails, and the sabre cut across one cheek, a dirty, lividwhite. i remember him looking round the cove and whistling to himselfas he did so, and then breaking out in that old sea-song that he sang sooften afterwards          fifteen men on the dead mans chest--             yo-ho-ho, and a bottle of rum!in the high, old tottering voice that seemed to have been tuned andbroken at the capstan bars. then he rapped on the door with a bit ofstick like a handspike that he carried, and when my father appeared,called roughly for a glass of rum. this, when it was brought to him,he drank slowly, like a connoisseur, lingering on the taste and stilllooking about him at the cliffs and up at our signboard.this is a handy cove, says he at length and a pleasant sittyatedgrog-shop. much company, matemy father told him no, very little company, the more was the pity.well, then, said he, this is the berth for me. here you, matey, hecried to the man who trundled the barrow bring up alongside and helpup my chest. ill stay here a bit, he continued. im a plain man rumand bacon and eggs is what i want, and that head up there for to watchships off. what you mought call me you mought call me captain. oh, isee what youre at--there and he threw down three or four gold pieceson the threshold. you can tell me when ive worked through that, sayshe, looking as fierce as a commander.and indeed bad as his clothes were and coarsely as he spoke, he had noneof the appearance of a man who sailed before the mast, but seemed likea mate or skipper accustomed to be obeyed or to strike. the man who camewith the barrow told us the mail had set him down the morning before atthe royal george, that he had inquired what inns there were along thecoast, and hearing ours well spoken of, i suppose, and described aslonely, had chosen it from the others for his place of residence. andthat was all we could learn of our guest.he was a very silent man by custom. all day he hung round the cove orupon the cliffs with a brass telescope all evening he sat in a cornerof the parlour next the fire and drank rum and water very strong. mostlyhe would not speak when spoken to, only look up sudden and fierce andblow through his nose like a fog-horn and we and the people who cameabout our house soon learned to let him be. every day when he came backfrom his stroll he would ask if any seafaring men had gone by along theroad. at first we thought it was the want of company of his own kindthat made him ask this question, but at last we began to see he wasdesirous to avoid them. when a seaman did put up at the admiral benbow(as now and then some did, making by the coast road for bristol) hewould look in at him through the curtained door before he entered theparlour and he was always sure to be as silent as a mouse when any suchwas present. for me, at least, there was no secret about the matter, fori was, in a way, a sharer in his alarms. he had taken me aside one dayand promised me a silver fourpenny on the first of every month if iwould only keep my weather-eye open for a seafaring man with one leg and let him know the moment he appeared. often enough when th\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAnIzz6HI36u",
        "outputId": "2c84e8a9-4dc2-4ad8-b029-54d8cdc7a290"
      },
      "source": [
        "chars = sorted(list(set(new_text)))\n",
        "print(chars)\n",
        "print(len(chars))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3NohacBJGJP",
        "outputId": "e772f592-0ff1-4abf-8137-c4780a3bfd4b"
      },
      "source": [
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "char_to_int"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " \"'\": 3,\n",
              " '(': 4,\n",
              " ')': 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " 'a': 9,\n",
              " 'b': 10,\n",
              " 'c': 11,\n",
              " 'd': 12,\n",
              " 'e': 13,\n",
              " 'f': 14,\n",
              " 'g': 15,\n",
              " 'h': 16,\n",
              " 'i': 17,\n",
              " 'j': 18,\n",
              " 'k': 19,\n",
              " 'l': 20,\n",
              " 'm': 21,\n",
              " 'n': 22,\n",
              " 'o': 23,\n",
              " 'p': 24,\n",
              " 'q': 25,\n",
              " 'r': 26,\n",
              " 's': 27,\n",
              " 't': 28,\n",
              " 'u': 29,\n",
              " 'v': 30,\n",
              " 'w': 31,\n",
              " 'x': 32,\n",
              " 'y': 33,\n",
              " 'z': 34}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghgkjRO1JIL3",
        "outputId": "4eee428b-7477-41d3-97ae-eb8d643d623f"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "int_to_char"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: '!',\n",
              " 2: '\"',\n",
              " 3: \"'\",\n",
              " 4: '(',\n",
              " 5: ')',\n",
              " 6: ',',\n",
              " 7: '-',\n",
              " 8: '.',\n",
              " 9: 'a',\n",
              " 10: 'b',\n",
              " 11: 'c',\n",
              " 12: 'd',\n",
              " 13: 'e',\n",
              " 14: 'f',\n",
              " 15: 'g',\n",
              " 16: 'h',\n",
              " 17: 'i',\n",
              " 18: 'j',\n",
              " 19: 'k',\n",
              " 20: 'l',\n",
              " 21: 'm',\n",
              " 22: 'n',\n",
              " 23: 'o',\n",
              " 24: 'p',\n",
              " 25: 'q',\n",
              " 26: 'r',\n",
              " 27: 's',\n",
              " 28: 't',\n",
              " 29: 'u',\n",
              " 30: 'v',\n",
              " 31: 'w',\n",
              " 32: 'x',\n",
              " 33: 'y',\n",
              " 34: 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipEmt6LCJKyj",
        "outputId": "53733db3-c89b-45b8-b684-40393bfecfe2"
      },
      "source": [
        "print('---Summary---')\n",
        "n_chars = len(new_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"corpus length by character \", n_chars)\n",
        "print(\"Vocab length: \", n_vocab)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---Summary---\n",
            "corpus length by character  370729\n",
            "Vocab length:  35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhD8ghmHJNx7"
      },
      "source": [
        "seq_length = 100 \n",
        "step_length = 10\n",
        "\n",
        "sentences = []    \n",
        "next_chars = []   \n",
        "\n",
        "for i in range(0, n_chars - seq_length, step_length): \n",
        "    sentences.append(new_text[i: i + seq_length])  #X\n",
        "    next_chars.append(new_text[i + seq_length])  #y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IjZHnUIJRyB",
        "outputId": "15fa7c46-835b-4f6f-982b-096a2d10ba4c"
      },
      "source": [
        "sentences[0:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of treasure island, by robert louis stevensonthis ebook is for the use o',\n",
              " 't gutenberg ebook of treasure island, by robert louis stevensonthis ebook is for the use of anyone a',\n",
              " 'g ebook of treasure island, by robert louis stevensonthis ebook is for the use of anyone anywhere in',\n",
              " ' treasure island, by robert louis stevensonthis ebook is for the use of anyone anywhere in the unite',\n",
              " 'island, by robert louis stevensonthis ebook is for the use of anyone anywhere in the united states a',\n",
              " ' robert louis stevensonthis ebook is for the use of anyone anywhere in the united states and mostoth',\n",
              " 'uis stevensonthis ebook is for the use of anyone anywhere in the united states and mostother parts o',\n",
              " 'sonthis ebook is for the use of anyone anywhere in the united states and mostother parts of the worl',\n",
              " 'ook is for the use of anyone anywhere in the united states and mostother parts of the world at no co',\n",
              " ' the use of anyone anywhere in the united states and mostother parts of the world at no cost and wit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXW7bvUwJXay",
        "outputId": "a763c00c-b44e-4ad8-d521-5b5696f42e8e"
      },
      "source": [
        "n_sentences = len(sentences)    # no of sentences \n",
        "n_sentences "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37063"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_k3OuyXJZcU"
      },
      "source": [
        "# creating a boolean array for each sentence, with no of characters as element\n",
        "\n",
        "x = np.zeros((n_sentences, seq_length, n_vocab), dtype=np.bool)\n",
        "y = np.zeros((n_sentences, n_vocab), dtype=np.bool)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EQjgPPZJbZD"
      },
      "source": [
        "# mapping chars to numbers\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_to_int[char]] = 1\n",
        "    y[i, char_to_int[next_chars[i]]] = 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td6eH2hrJepk",
        "outputId": "c4a2e057-3687-45dd-dae0-98935ff5c3d8"
      },
      "source": [
        "x.shape,y.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37063, 100, 35), (37063, 35))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhzAyUOmJgKY"
      },
      "source": [
        "# selecting the one with high prob like softmax\n",
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1) \n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaRBI5T1JsRj",
        "outputId": "1e8e7bec-d140-4660-83be-3eac1a9608c8"
      },
      "source": [
        "## Double layer lstm\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(seq_length, n_vocab), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(n_vocab, activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 128)          83968     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 35)                4515      \n",
            "=================================================================\n",
            "Total params: 220,067\n",
            "Trainable params: 220,067\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMibp6-OJzIZ"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhpgKhgEJ5-0",
        "outputId": "f7120aed-56ae-4116-ecde-bd4da831eb30"
      },
      "source": [
        "# Fit the model\n",
        "\n",
        "history = model.fit(x, y,batch_size=128,epochs=50,callbacks=callbacks_list)\n",
        "model.save('double_layer_lstm_50epochs.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "290/290 [==============================] - 38s 49ms/step - loss: 2.8190\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.50399, saving model to saved_weights/saved_weights-01-2.5040.hdf5\n",
            "Epoch 2/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 2.1023\n",
            "\n",
            "Epoch 00002: loss improved from 2.50399 to 2.05312, saving model to saved_weights/saved_weights-02-2.0531.hdf5\n",
            "Epoch 3/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.9185\n",
            "\n",
            "Epoch 00003: loss improved from 2.05312 to 1.90189, saving model to saved_weights/saved_weights-03-1.9019.hdf5\n",
            "Epoch 4/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.7935\n",
            "\n",
            "Epoch 00004: loss improved from 1.90189 to 1.79876, saving model to saved_weights/saved_weights-04-1.7988.hdf5\n",
            "Epoch 5/50\n",
            "290/290 [==============================] - 14s 50ms/step - loss: 1.7111\n",
            "\n",
            "Epoch 00005: loss improved from 1.79876 to 1.72041, saving model to saved_weights/saved_weights-05-1.7204.hdf5\n",
            "Epoch 6/50\n",
            "290/290 [==============================] - 14s 50ms/step - loss: 1.6337\n",
            "\n",
            "Epoch 00006: loss improved from 1.72041 to 1.65716, saving model to saved_weights/saved_weights-06-1.6572.hdf5\n",
            "Epoch 7/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.5843\n",
            "\n",
            "Epoch 00007: loss improved from 1.65716 to 1.60355, saving model to saved_weights/saved_weights-07-1.6036.hdf5\n",
            "Epoch 8/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.5442\n",
            "\n",
            "Epoch 00008: loss improved from 1.60355 to 1.56307, saving model to saved_weights/saved_weights-08-1.5631.hdf5\n",
            "Epoch 9/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.5062\n",
            "\n",
            "Epoch 00009: loss improved from 1.56307 to 1.52809, saving model to saved_weights/saved_weights-09-1.5281.hdf5\n",
            "Epoch 10/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.4591\n",
            "\n",
            "Epoch 00010: loss improved from 1.52809 to 1.49851, saving model to saved_weights/saved_weights-10-1.4985.hdf5\n",
            "Epoch 11/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.4380\n",
            "\n",
            "Epoch 00011: loss improved from 1.49851 to 1.46611, saving model to saved_weights/saved_weights-11-1.4661.hdf5\n",
            "Epoch 12/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.4020\n",
            "\n",
            "Epoch 00012: loss improved from 1.46611 to 1.43826, saving model to saved_weights/saved_weights-12-1.4383.hdf5\n",
            "Epoch 13/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.3929\n",
            "\n",
            "Epoch 00013: loss improved from 1.43826 to 1.42859, saving model to saved_weights/saved_weights-13-1.4286.hdf5\n",
            "Epoch 14/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.3612\n",
            "\n",
            "Epoch 00014: loss improved from 1.42859 to 1.40121, saving model to saved_weights/saved_weights-14-1.4012.hdf5\n",
            "Epoch 15/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.3395\n",
            "\n",
            "Epoch 00015: loss improved from 1.40121 to 1.37923, saving model to saved_weights/saved_weights-15-1.3792.hdf5\n",
            "Epoch 16/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.3286\n",
            "\n",
            "Epoch 00016: loss improved from 1.37923 to 1.36913, saving model to saved_weights/saved_weights-16-1.3691.hdf5\n",
            "Epoch 17/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.3276\n",
            "\n",
            "Epoch 00017: loss improved from 1.36913 to 1.35703, saving model to saved_weights/saved_weights-17-1.3570.hdf5\n",
            "Epoch 18/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.3074\n",
            "\n",
            "Epoch 00018: loss improved from 1.35703 to 1.34028, saving model to saved_weights/saved_weights-18-1.3403.hdf5\n",
            "Epoch 19/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.3033\n",
            "\n",
            "Epoch 00019: loss improved from 1.34028 to 1.33845, saving model to saved_weights/saved_weights-19-1.3384.hdf5\n",
            "Epoch 20/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2898\n",
            "\n",
            "Epoch 00020: loss improved from 1.33845 to 1.32333, saving model to saved_weights/saved_weights-20-1.3233.hdf5\n",
            "Epoch 21/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2766\n",
            "\n",
            "Epoch 00021: loss improved from 1.32333 to 1.31238, saving model to saved_weights/saved_weights-21-1.3124.hdf5\n",
            "Epoch 22/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2714\n",
            "\n",
            "Epoch 00022: loss improved from 1.31238 to 1.30257, saving model to saved_weights/saved_weights-22-1.3026.hdf5\n",
            "Epoch 23/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2526\n",
            "\n",
            "Epoch 00023: loss improved from 1.30257 to 1.28979, saving model to saved_weights/saved_weights-23-1.2898.hdf5\n",
            "Epoch 24/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2457\n",
            "\n",
            "Epoch 00024: loss improved from 1.28979 to 1.28083, saving model to saved_weights/saved_weights-24-1.2808.hdf5\n",
            "Epoch 25/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2340\n",
            "\n",
            "Epoch 00025: loss improved from 1.28083 to 1.27298, saving model to saved_weights/saved_weights-25-1.2730.hdf5\n",
            "Epoch 26/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2273\n",
            "\n",
            "Epoch 00026: loss improved from 1.27298 to 1.26186, saving model to saved_weights/saved_weights-26-1.2619.hdf5\n",
            "Epoch 27/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2193\n",
            "\n",
            "Epoch 00027: loss improved from 1.26186 to 1.26035, saving model to saved_weights/saved_weights-27-1.2604.hdf5\n",
            "Epoch 28/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2208\n",
            "\n",
            "Epoch 00028: loss improved from 1.26035 to 1.24641, saving model to saved_weights/saved_weights-28-1.2464.hdf5\n",
            "Epoch 29/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.2162\n",
            "\n",
            "Epoch 00029: loss improved from 1.24641 to 1.24339, saving model to saved_weights/saved_weights-29-1.2434.hdf5\n",
            "Epoch 30/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1826\n",
            "\n",
            "Epoch 00030: loss improved from 1.24339 to 1.22617, saving model to saved_weights/saved_weights-30-1.2262.hdf5\n",
            "Epoch 31/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1786\n",
            "\n",
            "Epoch 00031: loss improved from 1.22617 to 1.22368, saving model to saved_weights/saved_weights-31-1.2237.hdf5\n",
            "Epoch 32/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1790\n",
            "\n",
            "Epoch 00032: loss improved from 1.22368 to 1.21407, saving model to saved_weights/saved_weights-32-1.2141.hdf5\n",
            "Epoch 33/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1747\n",
            "\n",
            "Epoch 00033: loss improved from 1.21407 to 1.20943, saving model to saved_weights/saved_weights-33-1.2094.hdf5\n",
            "Epoch 34/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1628\n",
            "\n",
            "Epoch 00034: loss improved from 1.20943 to 1.19710, saving model to saved_weights/saved_weights-34-1.1971.hdf5\n",
            "Epoch 35/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1654\n",
            "\n",
            "Epoch 00035: loss improved from 1.19710 to 1.19515, saving model to saved_weights/saved_weights-35-1.1951.hdf5\n",
            "Epoch 36/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1707\n",
            "\n",
            "Epoch 00036: loss improved from 1.19515 to 1.18679, saving model to saved_weights/saved_weights-36-1.1868.hdf5\n",
            "Epoch 37/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1495\n",
            "\n",
            "Epoch 00037: loss improved from 1.18679 to 1.17860, saving model to saved_weights/saved_weights-37-1.1786.hdf5\n",
            "Epoch 38/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1358\n",
            "\n",
            "Epoch 00038: loss improved from 1.17860 to 1.17294, saving model to saved_weights/saved_weights-38-1.1729.hdf5\n",
            "Epoch 39/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1357\n",
            "\n",
            "Epoch 00039: loss improved from 1.17294 to 1.17047, saving model to saved_weights/saved_weights-39-1.1705.hdf5\n",
            "Epoch 40/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1123\n",
            "\n",
            "Epoch 00040: loss improved from 1.17047 to 1.15312, saving model to saved_weights/saved_weights-40-1.1531.hdf5\n",
            "Epoch 41/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1146\n",
            "\n",
            "Epoch 00041: loss improved from 1.15312 to 1.14720, saving model to saved_weights/saved_weights-41-1.1472.hdf5\n",
            "Epoch 42/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1252\n",
            "\n",
            "Epoch 00042: loss improved from 1.14720 to 1.14607, saving model to saved_weights/saved_weights-42-1.1461.hdf5\n",
            "Epoch 43/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.1175\n",
            "\n",
            "Epoch 00043: loss improved from 1.14607 to 1.14562, saving model to saved_weights/saved_weights-43-1.1456.hdf5\n",
            "Epoch 44/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1072\n",
            "\n",
            "Epoch 00044: loss improved from 1.14562 to 1.13419, saving model to saved_weights/saved_weights-44-1.1342.hdf5\n",
            "Epoch 45/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.1024\n",
            "\n",
            "Epoch 00045: loss improved from 1.13419 to 1.12587, saving model to saved_weights/saved_weights-45-1.1259.hdf5\n",
            "Epoch 46/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.0995\n",
            "\n",
            "Epoch 00046: loss improved from 1.12587 to 1.12405, saving model to saved_weights/saved_weights-46-1.1241.hdf5\n",
            "Epoch 47/50\n",
            "290/290 [==============================] - 14s 49ms/step - loss: 1.0853\n",
            "\n",
            "Epoch 00047: loss improved from 1.12405 to 1.11967, saving model to saved_weights/saved_weights-47-1.1197.hdf5\n",
            "Epoch 48/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.0842\n",
            "\n",
            "Epoch 00048: loss did not improve from 1.11967\n",
            "Epoch 49/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.0713\n",
            "\n",
            "Epoch 00049: loss improved from 1.11967 to 1.10434, saving model to saved_weights/saved_weights-49-1.1043.hdf5\n",
            "Epoch 50/50\n",
            "290/290 [==============================] - 14s 48ms/step - loss: 1.0585\n",
            "\n",
            "Epoch 00050: loss improved from 1.10434 to 1.09713, saving model to saved_weights/saved_weights-50-1.0971.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpi2xQ01J8sb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8d7d8e7f-8955-4850-def6-caadd60bd570"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bn38W8mGTIBiRCBEIaiooJGiaAgg7aVoc590YpAkQa1FqXVgtJT4dRTj0Ot2CIWIYJUkGohCCqUKQgGEjdkk4kwygwhkDAkECDDev94ThIRCAGyspKs3+e67mtPa2ffK8Z986xn8gEsRETEtXydTkBERJylQiAi4nIqBCIiLqdCICLicioEIiIup0IgIuJyKgTiel999RVDhw6t9mMvRe/evdmzZ0+1/1yRqvB3OgGRy5Gfn19+v3Hjxpw+fZqSkhIAnnrqKWbPnl3lnzVgwABbjhWpK1QIpE4KDg4uv79jxw5+9atfsXz58nOO8/PzKy8QInJ+ujQk9UrZJZYxY8Zw4MABpk+fTpMmTVi4cCE5OTnk5eWxcOFCWrVqVf6ehIQERowYAcCwYcNYvXo1b731Fnl5eXz33Xf069fvso5t27YtX3/9NcePH2fp0qVMmjSJf/7zn1U6j+uvv56EhASOHDlCRkYG9913X/lr/fv3JzMzk+PHj7N3715eeOEFAMLCwli4cCFHjhwhNzeXVatW4ePjc/m/THENFQKpdyIiImjWrBlRUVGMHDkSX19fpk+fTlRUFG3atKGwsJBJkyZd8P3dunVj8+bNhIeH8+abbxIXF3dZx86ePZtvv/2WsLAwJkyYwJAhQ6qUv7+/PwsXLmTJkiU0b96cUaNGMWvWLK699loA4uLieOqppwgJCeGmm25ixYoVALzwwgvs3buXq6++mhYtWjBu3DgsSyvIyMWpEEi9U1payvjx4zlz5gynTp0iLy+PefPmUVhYSEFBAX/+85/p3bv3Bd+/a9cupk2bRmlpKR999BEtW7akRYsWl3RsZGQkMTExvPLKKxQVFZGYmMiCBQuqlH/37t0JCgri9ddfp6ioiISEBL744gt+8YtfAFBUVMQNN9xAcHAwR48exev1lj9/zTXXEBUVRXFxMd98880l/ubErVQIpN45dOgQp0+fLn/cqFEj/vGPf7Bz506OHTvGqlWraNq0Kb6+5//zz87OLr9fWFgIQFBQ0CUd27JlS/Ly8sqfA6o8Kqhly5bs2bPnrH/N79q1q/xy1iOPPMKAAQPYtWsXK1eupHv37gC89dZbbNu2jSVLlrB9+3bGjh1bpc8TUSGQeueHl0NeeOEFrrvuOrp160ZoaCi9evUCsPX6+YEDB2jWrBmNGjUqfy4yMrJK792/fz+RkZFn5demTRv27dsHwLp163jwwQdp3rw58+fP59NPPwWgoKCAF198kQ4dOnD//ffzu9/9jrvvvrsaz0rqKxUCqfeCg4MpLCzk6NGjNG3alPHjx9v+mbt372bdunVMmDCBgIAAunfvflaHb2WSk5M5efIkY8aMwd/fn969e3PfffcxZ84cAgICePzxxwkJCaG4uJjjx49TWloKwMCBA+nQoQMAx44do6SkpPw1kcqoEEi9N3HiRBo1asThw4dJSkpi8eLFNfK5gwcP5o477iA3N5f/+Z//4V//+tdZl6wupKioiPvuu4/+/ftz+PBhJk+ezNChQ9m8eTMAQ4YMKb/M9fTTTzN48GAAOnbsyLJlyygoKGDt2rVMnjyZlStX2nmKUk/4oI1pRGrEnDlz2LRpExMmTHA6FZGzqEUgYpOuXbvSvn17fHx8uPfee3nggQeYP3++02mJnEMzi0VsEhERwbx58wgLC2Pv3r0888wzbNiwwem0RM6hS0MiIi6nS0MiIi5X5y4N5eTksGvXLqfTEBGpU6KiomjevPl5X6tzhWDXrl3ExMQ4nYaISJ3i8Xgu+JouDYmIuJwKgYiIy6kQiIi4XJ3rIxCR2qtp06aMHj2atm3balMcB1iWxc6dO5k4cSJHjhyp8vtUCESk2owePZp169bxpz/9SVuEOsDPz4+BAwcyevToS1pcUZeGRKTatG3blq+++kpFwCElJSV8+eWXtG3b9pLep0IgItXGx8dHRcBhJSUll3xZzjWFoF07GDECgoOdzkREpHZxTSFo1QqeeAIiIpzORETs0qxZM7xeL16vlwMHDrB3797yxwEBAZW+97bbbuPdd9+96GckJiZWS669e/dm4cKF1fKzrpRrOotzc81tWBhs3epsLiJij7y8PKKjowEYP348BQUFvP322+Wv+/n5XfDS1fr161m/fv1FP6NHjx7Vk2wt4poWQVkhaNbM2TxEpGZNnz6d999/n6SkJN58801iYmJYs2YNKSkpJCYmcu211wJn/wt9/PjxxMXFkZCQwPbt2xk1alT5z8vPzy8/PiEhgc8++4ysrCw+/vjj8mP69+9PVlYW69at4913373ov/ybNm1KfHw8qamprF27ls6dOwPQq1ev8hZNSkoKQUFBRERE8PXXX+P1eklPT6dnz55X/DtyTYsgL8/choU5m4eIWzz7LPzoR9X7M7dtg/feu/T3tW7dmjvvvJPS0lKCg4O56667KCkp4Z577uG1117j5z//+Tnvuf766+nbty/BwcFs3ryZ999/n+Li4rOOiY6O5sYbb2T//v0kJibSo0cP1q1bx5QpU+jVqxc7d+5k9uzZF83vv//7v/F6vTz00EP07duXmTNnEh0dzYsvvsizzz7LmjVrCAwM5NSpU4wcOZL//Oc/vPbaa/j6+tK4ceNL/4X8gGsKQXExHDumQiDiRp999hmlpaUAhIaG8tFHH9GxY0csy7pg38GXX37JmTNnyM3NJScnhxYtWrBv376zjvn222/Ln9uwYQNt27aloKCA7777jp07dwLwySefMHLkyErz69mzJ4888ggACQkJhIWFERwcTGJiIn/961+ZNWsW8+bNY9++fXg8Hj788EMCAgKYP38+qampV/KrAVxUCMBcHlIhEKkZl/Mvd7ucOHGi/P6rr75KQkICDz/8MFFRUaxcufK87zl9+nT5/ZKSEvz9z/26rMoxV+KNN97gyy+/ZMCAASQmJnLvvfeyevVqevXqxcCBA5kxYwZ//etf+ec//3lFn+OaPgJQIRAR0yIo+1f8L3/5y2r/+Zs3b6Z9+/ZERUUB8Oijj170PatXr2bw4MGA6Xs4fPgw+fn5tG/fnoyMDN588008Hg/XX389bdq04eDBg0ybNo1p06Zx6623XnHOrioEeXnqLBZxuzfffJP//d//JSUlpdr/BQ9w6tQpfv3rX7N48WLWrVtHfn4+x44dq/Q9EyZM4LbbbiM1NZXXX3+dYcOGAWbJjvT0dFJTUykqKmLRokX06dOH1NRUUlJSePTRR6s05LUqrLoUHo/nst8bG4u1ZInz56BQ1NeYOXOm4znUhggMDCy//95771mjR492/L9DZd+drmsRBARASIjTmYhIfRYbG4vX6yUzM5PQ0FCmTJnidEqVcl1nMZh+guPHnc1FROqviRMnMnHiRKfTqDJXtQgOHza36jAWsYdlWfj5+Tmdhqv5+flhWdYlvce2QtC6dWtWrFhBZmYmGRkZPPfccxc8tmvXrhQVFZWPo7WLJpWJ2Gvnzp0MHDhQxcAhZfsRlM1hqCrbLg0VFxfzwgsv4PV6CQoKYv369SxdupSsrKyzjvP19eWNN95gyZIldqVSTstMiNhr4sSJjB49mkceeUQ7lDng+zuUXQrbCkF2djbZ2dkAFBQUkJWVRatWrc4pBKNGjWLu3LnExMTYlUq506ehoADCw23/KBFXOnLkyCXtjCW1Q430EURFRREdHU1ycvJZz7ds2ZKHHnqI999/v9L3x8bG4vF48Hg8hF/ht7jmEoiInM32QhAYGMjcuXMZPXp0+ap9ZSZOnMjYsWMv2rExdepUYmJiiImJ4XBZj+9l0uxiEZGz2Tp81N/fn7lz5zJr1izi4+PPeb1r167MmTMHgPDwcAYMGEBxcTGff/65bTnl5cH119v240VE6hxbC0FcXBxZWVm888475329ffv25fenT5/OF198YWsRALUIRER+yLZC0KNHD4YOHUpaWhperxeAcePG0aZNGwDHZtrl5kLDhhAYCN9bkFBExLVsKwSJiYmXNHxs+PDhdqVylrK5BM2aqRCIiIDLZhaDZheLiPyQ6wrB99cbEhERFxYCLTMhInI21xWCEyfg1CkVAhGRMq4rBKAhpCIi3+fKQqBlJkREKriyEKhFICJSwZWFQC0CEZEKriwEubkQFAQNGjidiYiI81xbCECXh0REQIVARMT1VAhERFxOhUBExOVcWQiOH4eiIo0cEhEBlxYCMENI1SIQEXF5IVCLQETExYVAs4tFRAwVAhERl3NtIcjLg9BQCAhwOhMREWfZVghat27NihUryMzMJCMjg+eee+6cYx5//HFSU1NJS0sjMTGRLl262JXOOcqGkKqfQEQELDsiIiLCio6OtgArKCjI2rx5s9WpU6ezjrnjjjusJk2aWIDVr18/Kykp6aI/1+PxVEt+3btjJSRgdepkz/krFApFbYrKvjttaxFkZ2fj9XoBKCgoICsri1atWp11zNq1azl69CgASUlJtG7d2q50zqFJZSIihn9NfEhUVBTR0dEkJydf8JgRI0awaNGi874WGxvLyJEjAQgPD6+WnFQIREQq2NocCQwMtNatW2c99NBDFzymT58+1saNG61mzZpdUfPmUsLXF2vZMqzhw51vsikUCoXdUdl3p60tAn9/f+bOncusWbOIj48/7zGdO3dm2rRp9O/fn7y8PDvTOUtpKRw9qhaBiIitw0fj4uLIysrinXfeOe/rkZGRzJs3jyFDhrB161Y7UzkvzSUQEbGxj6BHjx4MHTqUtLS08k7jcePG0aZNGwCmTJnCK6+8QlhYGJMnTwaguLiYmJgYu1I6h5aZEBGxsRAkJibi4+NT6TGxsbHExsbalcJF5eZCx46OfbyISK3g2pnFYApB06bg6+rfgoi4nau/AnNzTRFo2tTpTEREnOP6QgDqMBYRd3N1ISgbraoOYxFxM1cXArUIRERcXgjKWgQqBCLiZq4uBMXFcOyYLg2JiLu5uhCAZheLiKgQqBCIiMu5vhDk5akQiIi7ub4Q5OaaPoKLrIYhIlJvqRDkgr8/hIQ4nYmIiDNUCDSXQERcToVAhUBEXM71heDwYXMbEeFsHiIiTnF9IcjOhpwc6NrV6UxERJzh+kIAkJwMt91mOo1FRNxGhQBISoLAQOjSxelMRERqngoBkJICZ85A9+5OZyIiUvNsKwStW7dmxYoVZGZmkpGRwXPPPXfe49599122bt1Kamoq0dHRdqVTqVOnIDUVunVz5ONFRBxn2RERERFWdHS0BVhBQUHW5s2brU6dOp11TP/+/a2vvvrKAqxu3bpZSUlJF/25Ho/HlnwffhgrIQGrZUt7fh8KhULhZFT23WlbiyA7Oxuv1wtAQUEBWVlZtGrV6qxjHnjgAWbOnAlAcnIyTZo0IcKhcZxJSeZWl4dExG1qpI8gKiqK6OhokpOTz3q+VatW7Nmzp/zx3r17zykWALGxsXg8HjweD+Hh4bbkuH8/7N6tQiAi7mN7IQgMDGTu3LmMHj2a/Pz8y/oZU6dOJSYmhpiYGA6XzQCzQVIS3HwzNGxo20eIiNQ6thYCf39/5s6dy6xZs4iPjz/n9X379hEZGVn+uHXr1uzbt8/OlCqVlARXXWXmFIiIuIWthSAuLo6srCzeeeed876+YMEChg4dCkC3bt04duwY2dnZdqZUqfR0OHFCo4dExF1sm0vbo0cPhg4dSlpaWnmn8bhx42jTpg0AU6ZM4auvvmLAgAFs27aNkydPMnz4cLvSqZLiYli/XoVARNzFtkKQmJiITxV2e/nNb35jVwqXJSkJevWCDh1g+3ansxERsZ9mFv+AhpGKiNuoEPzAkSOwebMuD4mIe6gQnEdyMtxwg7avFBF3UCE4j6Qk8PODmBinMxERsZ8KwXls2mQuEamfQETcQIXgPCwLvv3WtAh89RsSkXpOX3MXkJQEoaHQqZPTmYiI2EuF4AI8HigpgTvvdDoTERF7qRBcwIkTplXQrx8EBDidjYiIfVQIKjFvHjRrBn36OJ2JiIh9VAgqkZICO3fCI484nYmIiH1UCC4iPh6uu85MMBMRqY9UCC5iyRIoKICHH3Y6ExERe6gQXMSpU/DVV9C7N4SFOZ2NiEj1q1IhaNy4cfmS0h07duS+++7D39+2FaxrnfnzzcSy++93OhMRkepXpUKwatUqGjZsSMuWLVmyZAlDhgxhxowZNqdWexw4AGvXwn33aSipiNQ/VSoEPj4+FBYW8vDDDzN58mQGDRrEjTfeaHdutcq8edC0KfTt63QmIiLVq8qFoHv37gwePJgvv/wSAD8/P1sTq23KhpKq01hE6psqFYLRo0fz8ssvEx8fz8aNG2nXrh0JCQl251braCipiNRX1qWEj4+PFRwcfNHj4uLirIMHD1rp6ennfT0kJMRasGCBtWHDBisjI8P65S9/WaXP93g8l5RvdUbDhlgLF2L913858/kKhUJxuVHZd2eVWgSzZs0iODiYxo0bk5GRwcaNG3nxxRcrfc+MGTPo16/fBV9/9tln2bhxI7fccgt9+vTh7bffJqCW98R+fyhpeLjT2YiIVI8qFYIbbriB/Px8HnzwQRYtWkS7du0YMmRIpe9ZvXo1eXl5F3zdsiyCg4MBCAoKIi8vj+Li4ktI3RllQ0nvu8/pTEREqkeVCkFAQAD+/v48+OCDLFiwgOLiYizLuqIPnjRpEp06dWL//v2kp6fz/PPPX/BnxsbG4vF48Hg8hDv8T/EDB2DNGtNprD2NRaQ+qFIhmDJlCjt37iQwMJBVq1bRpk0bjh8/fkUffO+997JhwwZatmzJLbfcwqRJk8pbCD80depUYmJiiImJ4fDhw1f0udUhLg4aNYJhw5zORESkelxWx4Ofn99Fj4mKirpgZ/EXX3xh9ezZs/zx8uXLrZiYmCvq8KjJGD0aa9kyrMhI53NRKBSKi8UVdxaHhITw9ttvl1+e+ctf/kJgYGBV3npBu3fv5p577gGgefPmXHfddXz33XdX9DNr0owZUFgITz/tdCYiIlemSoXgww8/JD8/n0GDBjFo0CCOHz/O9OnTK33P7NmzWbt2Lddddx179uzhySef5KmnnuKpp54C4NVXX+XOO+8kLS2N5cuXM3bsWHJzc6/8jGrI0aMwa5bZyvLWW53ORkTkyly0SeH1eqv0XE1Ebbk0BFgBAVizZ2NNm4bl6+t8PgqFQnGhuOJLQ4WFhfTo0aP88Z133klhYWFV3lqvFRXBlCnQoYPZ21hEpC6q0lrSTz/9NDNnziQ0NBSAI0eOMExDZgD4+mtIT4cRIyAhwfQbiIjUJVVqEaSlpXHLLbfQpUsXunTpwq233srdd99td251xuTJZpP7xx93OhMRkUt3STuU5efnk5+fD8Dvfvc7WxKqizZtgqVLYdAgaNHC6WxERC7NZW9VWbZjmRjTpoFlQWys05mIiFyayy4EV7rERH2TkwP/+hfccw907+50NiIiVVdpZ/Hx48fP+4Xv4+NDo0aNbEuqrvr4Y+jRA37/e3jySTh2zOmMREQurtIWQUhICKGhoedESEhIrV8y2glFRfDnP0NQEFxklW4RkVrjsi8Nyfnt2GH6C3r2hAEDnM5GROTiVAhs8O9/mz2Of/MbaNnS6WxERCqnQmADy4LXX4eSEnj5ZbORjYhIbaWvKJscOgQTJ8JNN2mimYjUbioENlq+3MSwYXDttU5nIyJyfioENps4EfLy4A9/gIYNnc5GRORcKgQ2Kygw/QWtW8PYsaAJ2SJS26gQ1ACv1yxX3acPDBnidDYiImer0jLUcuU+/RTatYPhw2HnTli1yumMREQMtQhq0F//ChkZ8NJLZjMbEZHaQIWgBhUVwSuvQH6+WYqiaVOnMxIRsbEQxMXFcfDgQdLT0y94TO/evfF6vWRkZLBy5Uq7UqlVjhwxI4hCQ+FPfwIt2SQitYEtGyXfddddVnR0tJWenn7e10NDQ63MzEwrMjLSAqyrr776ijdgrkvRuzdWQgLWmDHO56JQKOp/XPHm9Zdj9erV5OXlXfD1xx9/nHnz5rFnzx4ADh06ZFcqtdLXX8NHH0H//ma/YxERpzjWR3DttdfStGlTEhISWLduHUMqGVcZGxuLx+PB4/EQHh5eg1na66OP4Isv4Ikn4Le/1ZpEIuIc25oiUVFRF7w09Pe//91au3at1bhxYyssLMzasmWL1bFjxytq3tTV+NWvzGWiCROwAgKcz0ehUNS/qOy707F5BHv37iU3N5eTJ09y8uRJVq1axc0338zWrVudSskx06bB0aPw7LMQHAx//COcPOl0ViLiFo5djPj888/p2bMnfn5+NGrUiG7dupGVleVUOo7797/NkNIuXeCdd6BJE6czEhG3sK1FMHv2bPr06UN4eDh79uxh/Pjx5dtbTpkyhU2bNrF48WLS0tIoLS1l2rRpZGZm2pVOnbBsmZljMGEC/P3vZu/j7GynsxIRN3D82tWlRH3sI/hh3Hgj1oIFWPHxWNHRzuejUCjqfjgyfFQuX2Ym/PrXpt/grbdg0CCnMxKR+kyFoJbau9cUg2++gWeeMR3I2s9AROygQlCLFRaa/oIpU6B3b3jvPWjZ0umsRKS+USGoA+bMMZvahIWZonDHHU5nJCL1iQpBHbF+PTz1FOzfD6+9Bi++CIGBTmclIvWBCkEdcvAg/OY3MHs29OsHH34IXbs6nZWI1HUqBHVMURFMnQqjRpk+hLfeghdegMaNnc5MROoqFYI6KisLYmPhk0/MCqYffgi33eZ0ViJSF6kQ1GFFRfDBB6Z1cOoU/OUv8PTT4K+dqEXkEqgQ1ANZWTByJMTHw6OPmuUpNMxURKpKhaCeOHMG/vY3M/GsVSvTUrj7bqezEpG6QIWgnvnmG/jVr+C770xRGDNGM5JFpHIqBPVQTg6MHg0zZ8K998I//gGdOjmdlYjUVioE9VRpKUyfbiaeNWoEkybBc89pmKmInEuFoJ7zeuGXvzQdyQ88ADNmQM+eTmclIrWJCoELFBaaFsGzz8KxY/DqqybCw53OTERqA404d5FNm8w8g//3/2DYMPjoI/j6a9i40cTOneaSkoi4iwqBy5SUmNVMv/7ajC664w4zMxlMyyEry8SqVbBli7O5ikjNUCFwqQMHzOUhMJPPbrjBjCy64QYzKe0Xv4CFC826RidOOJuriNjPlv0x4+LirIMHD1rp6emVHte1a1erqKjIeuSRR654301F9URgINazz2ItW4b1739j9e3rfE4KheLKwpE9i2fMmEG/fv0qPcbX15c33niDJUuW2JWGXIYTJ8xuaL/+NRw6BK+8Am++qWUrROor2wrB6tWrycvLq/SYUaNGMXfuXHJycuxKQ67Ali1mpNG775pLRtOnm05mzUUQqV8cGz7asmVLHnroId5///2LHhsbG4vH48Hj8RCuMY81qrQU5s83BeCbb8ychE8+gSFDtEOaSH3hWCGYOHEiY8eOxbKsix47depUYmJiiImJ4fDhwzWQnfxQbq7pXH7qKUhPhyefNAVh6FAVBJG6zrFRQ127dmXOnDkAhIeHM2DAAIqLi/n888+dSkmqYMsW+K//gh/9yBSB4cPNvIT58+Hbb2HzZrMSqojUHY4Vgvbt25ffnz59Ol988YWKQB2ybZvpRO7QwRSEJ54wUVQEW7dCRkZFHDnidLYiUhnbCsHs2bPp06cP4eHh7Nmzh/HjxxMQEADAlClT7PpYqWHbt8P48RAaCjfeCDfdZG4ffBAGDTLH7NgB69aBxwNpaXD6tLM5i8jZfDDjSOsMj8dDTEyM02nIRfj7Q8eO0KWL2Uu5Sxdo0MBcNkpPN4Vh1SrYv9/pTEXcobLvThUCqRFXXWWKQdeuJjp0MM+npcHixbBypVniQkTsUdl3p5aYkBpx5oxpBaxbZx6Hh8OPf2zWORozBkaNMusfLV4MqanO5iriNioE4ojDh83id3PmmMlq/ftD377Qrx8UF8OpUxVx+rRpLRw+DKtXw5o15nkRqR4qBOK4smWwJ02Cu+6Ctm3NPssNGpjd1Ro0MI9vvBH69DFFICkJEhLMrYarilwZFQKpNU6fhmXLLvy6j48ZldS3L/TubYrCyZOmhbB+PWzYANnZNZauSL2hQiB1hmWZEUfp6ab1cMstpij06GH6GwAOHjR9DKmppjBoVJLIxakQSJ1UWgopKSbefttcTrr5ZlMcunaFn/7UHJeXZy47ZWaaDXc2bdI8BpEfUiGQemHnThNlk9PbtDGF4cYbTWd0z57m+ZISMwnO64XkZNO6KC52KmuR2kGFQOql3btNLFxoHoeEmIJwww2mODz0kNmJ7eRJM6Q1OdmslaQ1DcWNVAjEFY4fNyOMkpLM44YN4dZboVs3E716med37TIL55XFtm26lCT1nwqBuNKpU2a00Zo15nHbttC9uxmVdNttFX0MJSXmktPWreaS0nffmTh61KnMRaqfCoEIFX0MZcLC4LrrTFx7Ldx+u5nsViYvzxSE7dtNP0NaGuTn13TWItVDhUDkPHJzz24xADRpAu3bQ7t2Zq2kdu3MKquPPmpGMW3fboaslg1fLShwLn+RS6FCIFJFR49WDFkt4+8P119vhq3ecgvcf7/ZqAfMshhnzpg+htOnzf0zZ0zLIzHRLMutWdFSG6gQiFyB4uKKDXg+/hgCAkxh6NzZjFRq0MDEVVdVLJVx111mbaXCQlMMvvkG1q5VC0Kco0IgUo2KiipmP1+In59pPdx1l5kV3auXKSjbt8OxY6av4ftx6JAZ7aSF9sQuKgQiNaykxKyNtH49vPuuaUH07Gn2gQ4OhmuuMa2JoCBTNABOnDCL7H35pZkdLVKdVAhEHGRZZumLrKxzX/PxgcaNTQd1//5wzz3ws5+ZlsOiRbB0qZkfIXKltEOZSB3RuDHcfTcMGACdOpmWxfHjZnb0iRMmyu7v3m3WWNq0STu/ieHIDmVxcfY8Bu0AAAvVSURBVHH87Gc/Iycnh86dO5/z+uOPP87YsWPx8fEhPz+fZ555hrS0NLvSEanzTp6EL74w0aGD6VsIDYXAQFMkAgOhRQtzSalsQlxpqRmltHGjaXXs2GGW0cjLM4VEBGwsBDNmzGDSpEnMnDnzvK/v2LGD3r17c/ToUfr168cHH3xA9+7d7UpHpF7Zvt3EhQQFmVZDp05mfaVevcxlpTKlpXDkiCkKhw/D3r2mzyI1VUNa3ci2QrB69WqioqIu+PratWvL7yclJdG6dWu7UhFxnYICMzTV46l4rnVrE+HhZ0dEBMTEmIlxp0+bYuDxmEX4du927hyk5tSKzuIRI0awaNGiC74eGxvLyJEjAQgPD6+ptETqlb17TZxPgwZm2e6YGBPPPmsiL8/0Q5w6ZfoayvaRPnnSFIlt20yo07puc7wQ9OnThxEjRtCzbMH485g6dSpTp04FTIeHiFSv06dNC+Dbb83jFi1MQbjhBtP/0LChibAwcxsUBAMHVrw/J6diYb6y4pCdbUZFSe3naCHo3Lkz06ZNo3///uTl5TmZioh8z8GDFR3TFxISYuY+lEXHjmYF1+/PfSjry9i+3SzxfeCAaWWoQNQujhWCyMhI5s2bx5AhQ9i6datTaYjIZTp+/Ny1l666qmJRvh/9yNz+9KdmRFOZM2dMa+HAAXN76JApGgUFFcNfT540azsdOlTz5+VGthWC2bNn06dPH8LDw9mzZw/jx48nICAAgClTpvDKK68QFhbG5MmTASguLtb8AJE67syZik19yvj4mA7pyEgzazoiwsQ115hZ1aGhF/55WVlmNvWKFZoPYSdNKBMRRwUEVMyFCAqqmBPRqpWZUd22rSkCy5fDV1+dfxa2XJwjE8pERKqiqMhcBjrfrm+ffmo6rAcOrFhi47vvIDMT9u83ceCAuT1xouZzry9UCESkVtu40cR775klNn78Y7Nya5MmZx9XtnJrcbG5RFVcbIpMUZG5X1pqOqlLSirunzhhVopNSTET69xKhUBE6oTvL7EB5hLSNddAy5YVt0FBZrOggICKaNjQPOfre240aVIx43r3bvB6K8JNcyNUCESkTjp58uJLbVyMj49Z3fXWWyE6Gn7yE3jgAfPagQPnzo3Iyame3GsbFQIRcS3Lqigmn31m5kBce62ZZd2xoxkC27OnaT2AaSUcOWIm4BUWmtuy2db5+RUL+uXmVsSJExUtED8/E76+5pJVbRkJpUIgIvJ/SkrO3R+iYUPTaiibFxEcbJ5r0MDcDw83j8s2E7qUz0pJMftKrF7t7A50KgQiIpU4daqiw/piGjaEZs1McQgLM/cDA82Xflknddn9sDDT+T1unGkZfPONKQrr15vjapIKgYhINTl1qmJYa1XExcFNN5m+iT59zG1eHmzZYvaR2LXLxO7d9g6PVSEQEXFQRoaJSZPg9tvN3hFlHdhXXVVx3KFDph/js8+qPwcVAhGRWqCoCBITTYDpUI6IMDOr27Qxt3atzalCICJSC5WWVlxmWrPG3s/ytffHi4hIbadCICLicioEIiIup0IgIuJyKgQiIi6nQiAi4nIqBCIiLqdCICLicnVuz+KcnBx27dpV6THh4eEcduF2Qzpv93Hrueu8L11UVBTNmze/4OtWfQuPx+N4DjpvnbfOXeddV85bl4ZERFxOhUBExOX8gAlOJ2GHlJQUp1NwhM7bfdx67jrv6lPnOotFRKR66dKQiIjLqRCIiLhcvSsE9957L5s2bWLr1q2MHTvW6XRsExcXx8GDB0lPTy9/rmnTpixZsoQtW7awZMkSmjRp4mCG9mjdujUrVqwgMzOTjIwMnnvuOaD+n3uDBg1ITk5mw4YNZGRkMGHCBADatm1LUlISW7duZc6cOQQEBDibqE18fX1JSUlh4cKFgDvOe8eOHaSlpeH1evF4PIC9f+eOj42trvD19bW2bdtmtWvXzgoICLA2bNhgderUyfG87Ii77rrLio6OttLT08ufe+ONN6yxY8dagDV27Fjr9ddfdzzP6o6IiAgrOjraAqygoCBr8+bNVqdOnVxx7oGBgRZg+fv7W0lJSVa3bt2sf/3rX9ajjz5qAdb7779vPf30047naUf89re/tWbNmmUtXLjQAlxx3jt27LDCwsLOes7Gv3PnT7i6onv37tbixYvLH7/00kvWSy+95HhedkVUVNRZhWDTpk1WRESEBeYLc9OmTY7naHfMnz/f+vGPf+yqc2/UqJG1fv166/bbb7cOHTpk+fn5WXDu3399iVatWlnLli2z+vbtW14I3HDe5ysEdv2d16tLQ61atWLPnj3lj/fu3UurVq0czKhmtWjRguzsbACys7Np0aKFwxnZKyoqiujoaJKTk11x7r6+vni9XnJycli6dCnbt2/n6NGjlJSUAPX3733ixImMGTOG0tJSAMLCwlxx3pZlsWTJEtatW0dsbCxg3//j2ry+HrMsy+kUbBMYGMjcuXMZPXo0+fn557xeH8+9tLSU6OhoQkNDiY+P5/rrr3c6JdsNHDiQnJwcUlJS6N27t9Pp1KiePXuyf/9+rr76apYuXcqmTZvOOaa6/s7rVSHYt28fkZGR5Y9bt27Nvn37HMyoZh08eJCIiAiys7OJiIggJyfH6ZRs4e/vz9y5c5k1axbx8fGAe84d4NixYyQkJHDHHXfQpEkT/Pz8KCkpqZd/7z169OD+++9nwIABNGzYkJCQEN599916f94A+/fvB+DQoUPEx8dz++232/Z3Xq8uDXk8Hjp27Ejbtm0JCAjgscceY8GCBU6nVWMWLFjAsGHDABg2bBiff/65wxnZIy4ujqysLN55553y5+r7uYeHhxMaGgpAw4YN+clPfkJWVhYJCQn8/Oc/B+rneY8bN47IyEjatWvHY489xooVK3jiiSfq/Xk3btyYoKCg8vs//elPycjIsPXv3PFOkeqM/v37W5s3b7a2bdtmjRs3zvF87IrZs2db+/fvt86cOWPt2bPHevLJJ61mzZpZy5Yts7Zs2WItXbrUatq0qeN5Vnf06NHDsizLSk1Ntbxer+X1eq3+/fvX+3Pv3LmzlZKSYqWmplrp6enWH//4Rwuw2rVrZyUnJ1tbt261Pv30U+uqq65yPFe7onfv3uWdxfX9vNu1a2dt2LDB2rBhg5WRkVH+XWbX37mWmBARcbl6dWlIREQunQqBiIjLqRCIiLicCoGIiMupEIiIuJwKgcj/KS4uxuv1lkd1rl4bFRV11kqxIrVJvZpZLHIlCgsLiY6OdjoNkRqnFoHIRezYsYM33niDtLQ0kpOT6dChA2D+lb98+XJSU1NZtmxZ+fImzZs3Z968eWzYsIENGzZwxx13AODn58cHH3xARkYG//nPf2jYsCEAo0aNIjMzk9TUVD755BNnTlJcz/FZdApFbYji4uLy2cper9caNGiQBWY54LKZnUOGDCmf3bpgwQJr6NChFmANHz7cio+PtwBrzpw51vPPP2+B2SMjJCTEioqKsoqKiqybb77ZArOe/uDBgy3A2rdvX/nM2NDQUMd/DwpXhuMJKBS1IvLz88/7/I4dO6x27dpZYDaFOXz4sAVmTXx/f//y5w8dOmQBVk5OzjlLHkRFRVlbtmwpfzxmzBjrD3/4gwVYixYtsj777DNr8ODB5ZvPKBQ1Gbo0JFIF31/u93KX/j19+nT5/ZKSEvz9TRfdwIEDee+997j11lvxeDz4+fldWbIil0iFQKQKHn300fLbtWvXArBmzRoee+wxAAYPHszq1asBWL58Oc888wxgNpMJCQm54M/18fEhMjKSlStXMnbsWEJDQ8tXnRSpKRo1JPJ/GjVqhNfrLX+8ePFiXn75ZcBsGp6amsrp06f5xS9+AZhO3unTp/P73/+eQ4cOMXz4cACef/55PvjgA0aMGEFJSQnPPPMMBw4cOO9n+vn58fHHHxMaGoqPjw9/+9vfOHbsmM1nKnI2rT4qchE7duyga9eu5ObmOp2KiC10aUhExOXUIhARcTm1CEREXE6FQETE5VQIRERcToVARMTlVAhERFzu/wOxYx8QxFuEwQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IILiwR1Pzm3l"
      },
      "source": [
        "def fin_pred(preds):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds)\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1) \n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJPPedY0E3-",
        "outputId": "3f1076af-f513-4067-8e40-b045f0ed59ae"
      },
      "source": [
        "def output(char_len):\n",
        "  start_index = random.randint(0, n_chars - seq_length - 1)\n",
        "  generated_text =''\n",
        "  sentence= raw_text[start_index: start_index + seq_length]\n",
        "  generated_text += sentence\n",
        "  print(\" Seed for prediction: \"+sentence + \"--->\")\n",
        "  for i in range(char_len):\n",
        "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
        "    for t, char in enumerate(sentence):\n",
        "      red_list = [\"\\n\",\"'\",';','\"']\n",
        "      if char not in red_list:\n",
        "        x_pred[0, t, char_to_int[char]] = 1.\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = fin_pred(preds)\n",
        "    next_char = int_to_char[next_index]\n",
        "\n",
        "    generated_text += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "print()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN8tPzDB2AXD",
        "outputId": "02a4c77b-473f-431f-ec2d-08df77f8d8b7"
      },
      "source": [
        "output(400)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Seed for prediction: a live thing in the scuppers.\n",
            "\n",
            "suddenly the hispaniola came right into the wind. the jibs behind me\n",
            "--->\n",
            "repland.or of this . and side, like a mutpase to vave a give him we could see the mething        reheld the inn this strong below i should five caped away all to, firs the hat down i regarse after but slee a doubleother, betwing this nothing i could or to be isgan, seemed between up his cruech should dust, and like themisher--on his and a deast flan than had long jive oy. when i cant leaved to it "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBeL6A5V2N_n",
        "outputId": "9cd4b44f-ed6e-4aa7-8b65-fc2187348744"
      },
      "source": [
        "gen = output(10000)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Seed for prediction: nd the rest eddied about the house and kept us coughing and piping\n",
            "the eye.\n",
            "\n",
            "add to this that gray, --->\n",
            "the were upon that pirce the side stood bent to the mame, whre had not hreen that is have since like a duit of the sail man, and it we could see his post a last i could reat side falle a side and there for the lockoh, with dlind awwerned it said he, and i saved the opened, and there come think went, fringtorgether of the captain hisstarce and treturn, we took the barkshow may of the other side dair, but silver himself to when i to kee down scalled the crairecuate of the hills capns to i could he was not uit and nowhen co dared the turse had sust at we all me sine to and thecet at leperhape who the pock in the man to the sun for seaman to thats so rast a cook sbotionly shebesating surparce and i bullation for like amos. i dont had and gune, sir, and i save i say seen to grot, a peatring and could was bit three were left in the orrare down to the full pintry wasce as the raphort.the captains of all the fore capn sinturn, and he clisading for us goad hands we keed, a partice of you sumpe cook, you old sil. you fill the cabinced by ruw for side and into the treasure i could low estarches thust other and belack word mahe headd was bossly tall treabugains, comnanyhy.when ah, belough i ancuce and a last i mich like as.pleptred.well, i say sand when we haw throwes know would the lust should i had all ole dont lay into the sut back you, i gusted to and neesion down that pilcus of the hand, here for theregrome surines. which bearshing you said the prant, parts gaired in a this fire or day to ringet in the hert, fan the flat of the sist, and they were silvers jombed bras, and when far your captain. mened a nast on seach seate, perhaps and had fellow and but sit he would bot a platted of mate, and its been who mought up a sut down that dunt of birdhad if and ment. the should dethy awands on ut at the shipsed and possed on the maunursed, and you dead, and he dother with a like aptain sometime, , rations as thecooring a great tre appearst and creatly i was, i could neven you and i redows the the fires was thick a turned the neftr shought we oodand stirrstpire and nothing we could beand hef a word of the till the math, and you must into this clessthosly approceed.for it was nothout sircerous, not you! it was not the chice of bundint down to that he had towy istance been against for the work of the o firs it if and i rades !emen of moviy were for his barce in the cabinhhad the should when they from the whole shell to the tireowarce, and when i want to be under this nege benw, after vropet in the shipped, at save, the treasure.returned rates and me it was seawas brigcunder as the head of his breat head side of the sime, and it the bolt may on the spoke down that aor the companited groars. now, itthe should tell you it wet earried the captainss and pucted in the like-asay.were side.alrack wold do without since sudden obedioced up the cabin.again  so corsed their stool of the swigh of his neate. so much with cleavly it was coside to rinding leatestrong once down that had a good as i do breation, to by so may was the piot in. i reither handsbrad by without send appears after three from the order.if one to fill in the treasure, nothing sward and still bes windour.inquild a coundrishe, as thest quire as silver, pronitked and benpore that dring. when the boat, and now ive slee o. the cried.forthe, here, wereswaids, i should filling if the stockadeat of around out for this creasure--they falle the i had thevery till freen to me from the asked, and possed inthe eclose that very foom, and near of my.hes, captain, and ceptain  sland might to we fell he were.re up for this with mover of a feat his apreak which would have cauld here or have scrutcex cantecure and telle when the captain, he corat, and another right . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      .f be repting boat its only the stick could you ships--lays mus, from the spike as he coll, and his here.there, and mayber fungly shail. rations or for bar after sban i profect gutenberg-tm nagate, and when he cant her morganles in the bill, and onied of his byagans low say, mere freep and pelthnow had his found andbe determe a look a ba-comuass. now, all one none and the bords that     wherether colland couned right was platt in           ein one the ambing mrumbht see on her,  cling time me. should still through the mither in the twop of his ladmince what i had perpint of the hispaniola was to keap. handsbride where the forely, so fide here, as made i reenlave. you things from the company,leass. how prace flewhen we wasnot a dires. it was not renthing.i was in a dind, a sade neet the anchoing shooly groved you cant have partered the procectribution of the side of this cruisious churssill hes of a hot--board.and clear of his confill. mk weft, the squire.and the matt, after a little thimbed away aput on your capnate in the two hure a-your for to cappling along then as i behem, here. if it up sintirulats that perhouse, you can at he saids the captain thecoal at the boldyouvely you was that of the thirajty, you chocust it was fortred, you farterd palld crathed in a last not me that imlendantion for his nother upon, he handss wrutcemen to be it says the doctor. his cruth it was the namen could was not there may strike the leasan whun we rears, a bottled it, cabitter, which that hand carried them the chort at the recrecull of the tree of hour, plutted sise amingwithent of their head the other, the doctor, his muinly this pigsing it never seen towhere was it with the tew of oat a sattart a possed in a tunt.whot or a vadfoo as she could i saod shall hard faperes canpist black vosch faghere, become. i post of us under the asked dlad i aright down,wher clied to  usrupens brus to     precepted by all the plant and say with mt goad, and shipn a long back up his unacher upon this ships approared bering--babecured searactly, the buckning.dsight lay been of the crocks when the sterewsome round of the pullation and when a couck had drind and when i was not when mouthout the word nest, and i had sith mistation, anythes upre, to here he cross but good death, flueted first and relive a mynaw--land.saves that thest companysorchonse--sounding him here ip handsbut with a enight of the shouldent of the old said. jisting the min had the cimpaniorh. withaatto may, among the one pointerse must of the stockade and a bottle, it was sitred silver, arwards you ave or benrent has been of his beat hasse, and if his this barrew when a sat dew prepting bomemselly plant. the captain, if and the fire sever with a biffer into the last, and these craike post part, seave the. , long bonet on along for the ship, here a sunding plarg of the him, wo had to be about him, he had pock swung at men on one cheel.i saw econdirly, there had scoared the sent unoull been and rught. when they here, before as recuence soull be in the house and the resguined the pare of the planced to the boats or mich there, man to before and well the doctorbilie his conves out of the turned at last to we have. or the side on the twop applew, and as the tright of desige look away, and down, i say one thing. who was but .                                       herent where, bucline and if thundernt, it dont nat made his cruscuse mut sudpust ustal in a plate upon a one to still well, and moved hat he had gone would like a mindmy wasnt that purce stillget onlement youll forthe fice piecosss, and the itrance of the spreis of poor thebefromby me corner shame, and with a compoly made of truch repect and youll fient handswa dads gunn--a spite was on proclossas on a nambed it the seavam and srike his own ghes--staying be. and i hear the dire sometime holder to fellhind thecross theymorders decton and if the man her, and defect it upon the would say here trelawn i could he had mate, and i could stay he was, and shem a dife there applant. he man, dont we me -pain, conturit, it was it at the mother good stail when he cant only barred his arantch of this mouthous now, sir.thingas bolition of the off, drinks standing i began to wreck of ex inhad fellowed then the booty, yourage bent groy, had ipme a little that icouded that ewcents poss to a laycous to they coll, and he capn of dound and well, which it was above all want at the poor in the old slike a litthen, who had likens, belogh low of the creadly elfacling rightly was on do who the stockadeword and the feat swould be in his ment in the coping to his possiolly goad that ill silver, i seen like abon the squire. but hanlut had eyteen, who done and now pile to course on the dillsseate--but had the pipling i looked on the old me was a may of capnas but we peral clusing andthing one murhing nother, behind her his, some shade side, and may of the off trying the lecked.i post to sit down, now, om their, and lite and long posed i heard hearrdide as i had likewasthewood counded to rublen seen the rim,warked.and chonsed and acreat of the dike and bencege this boar. thes floot sometime withamberfer to donat manwas peacered foundation a new of the treasure, he didnown gunn, continup, he sapped, seath feet that my ofthe matter and a visate. not had a nangy couonped the hold say the rime craise, but prace captain hoard, i clide returned his moust hoith of the stockage, that party, but the manage to his orhands were did pispossion, though he but the stockade in morning he wasnong our escums of the surposes and these frruth sine of the terme were sonso on a blind and with the island, very suld sure eathing when the mother very me, and you turned ecton on fount that was you oll some doctor. he cantered or even at parrice and in ladmint, and hands we could see whistleden as a meter, but it at the twof in a dilk stand. where the hours.jebtribution of the ent.down to be al was silver and sown men, when the house.foreward and if the ill it a tadet buchourss and bennot ownen silver youre he dending the right and soon and call place in the far ta, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k1n3_cJ2qDL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}