{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Textual Similarity.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fHTtwvl5ipi"
      },
      "source": [
        "# **Semantic Textual Similarity**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWRHl2I35w0D",
        "outputId": "eeabbf3b-4228-498f-e5a0-ff9e26d2603c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_9vj7Jk520W"
      },
      "source": [
        "# IMPORTS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import scipy.spatial\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45dDewe06Bf3"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/Text_Similarity_Dataset.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VtOOhtpg6H8w",
        "outputId": "c6366c36-8970-4a37-f8e5-544cb3edb28b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
              "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
              "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
              "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
              "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>be careful how you code a new european directi...</td>\n",
              "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  ...                                              text2\n",
              "0          0  ...  newcastle 2-1 bolton kieron dyer smashed home ...\n",
              "1          1  ...  nasdaq planning $100m share sale the owner of ...\n",
              "2          2  ...  ruddock backs yapp s credentials wales coach m...\n",
              "3          3  ...  mci shares climb on takeover bid shares in us ...\n",
              "4          4  ...  media gadgets get moving pocket-sized devices ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4efMCZT6KCL",
        "outputId": "a6ee9282-177f-48cd-a40b-cc227d86ea44"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unique_ID    0\n",
              "text1        0\n",
              "text2        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ITi1yeF76kW"
      },
      "source": [
        "### Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mownXidw6V88",
        "outputId": "b527768f-c271-4f9a-b943-e82fd3da52ad"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4023, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH0Is6AO6YqE"
      },
      "source": [
        "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python'''\n",
        "contractions = { \n",
        "\"ain't\": \"am not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"needn't\": \"need not\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there had\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who's\": \"who is\",\n",
        "\"won't\": \"will not\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you're\": \"you are\"\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83TYL9CK6iLq"
      },
      "source": [
        "def clean_text(text, remove_stopwords):\n",
        "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
        "    \n",
        "    # Convert words to lower case\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Replace contractions with their longer forms \n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "    \n",
        "    # remove special characters\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "\n",
        "    # lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_list = nltk.word_tokenize(text)\n",
        "    text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "\n",
        "    \n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        text = text.split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "        text = \" \".join(text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llIFDs0N6tIh",
        "outputId": "112f03f8-9c37-4cac-8eec-619eb87c526c"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXpDPWy56wn1"
      },
      "source": [
        "# data cleaning\n",
        "\n",
        "Clean_text1 = []\n",
        "for texts in data.text1:\n",
        "  Clean_text1.append(clean_text(str(texts), remove_stopwords=False)) # stop words might bear data\n",
        "\n",
        "Clean_text2 = []\n",
        "for texts in data.text2:\n",
        "  Clean_text2.append(clean_text(str(texts), remove_stopwords=False))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW-2AyLt68yz"
      },
      "source": [
        "data['text1']= Clean_text1\n",
        "data['text2']= Clean_text2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zTX-cgrN7B88",
        "outputId": "2bf54887-4a0d-47c3-f334-325136c9c105"
      },
      "source": [
        "sim = data    # cleaned data in sim df\n",
        "sim.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>savvy searcher fail to spot ad internet search...</td>\n",
              "      <td>newcastle 2 1 bolton kieron dyer smashed home ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>million to miss out on the net by 2025 40 of t...</td>\n",
              "      <td>nasdaq planning 100m share sale the owner of t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>young debut cut short by ginepri fifteen year ...</td>\n",
              "      <td>ruddock back yapp s credential wale coach mike...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>diageo to buy u wine firm diageo the world s b...</td>\n",
              "      <td>mci share climb on takeover bid share in u pho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>be careful how you code a new european directi...</td>\n",
              "      <td>medium gadget get moving pocket sized device t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  ...                                              text2\n",
              "0          0  ...  newcastle 2 1 bolton kieron dyer smashed home ...\n",
              "1          1  ...  nasdaq planning 100m share sale the owner of t...\n",
              "2          2  ...  ruddock back yapp s credential wale coach mike...\n",
              "3          3  ...  mci share climb on takeover bid share in u pho...\n",
              "4          4  ...  medium gadget get moving pocket sized device t...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-AMK95Z7FI5",
        "outputId": "653c784d-7733-4ed1-b42b-e843484cb3e1"
      },
      "source": [
        "# duplicate check\n",
        "dup = 0\n",
        "for i in range(len(sim['text1'])):\n",
        "    if sim['text1'][i]==sim['text2'][i]:\n",
        "      print(i)\n",
        "      dup+=1\n",
        "print(dup)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3403\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "B1fDazmB7iEk",
        "outputId": "018e7ca5-c73c-40af-ec66-354dd75ef244"
      },
      "source": [
        "sim.text1[3403]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'holmes start 2005 with gb event kelly holmes will start 2005 with a series of race in britain holmes will make her first track appearance on home soil since winning double olympic gold in january s norwich union international in glasgow she will also run in the grand prix in birmingham in february and may defend her indoor aaa 800m title in sheffield earlier that month i am still competitive and still want to win she said i m an athlete and i can t wait to get back on the track she added these event are also a great opportunity to thank the british public for the enormous level of support they have given me from the moment i stepped off that plane from greece the glasgow meeting will see holmes compete over 1500m in a five way match against sweden france russia and italy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "B7u9RZis7lFV",
        "outputId": "3c553efc-4ff7-4133-de52-b95095cf223c"
      },
      "source": [
        "sim.text2[3403]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'holmes start 2005 with gb event kelly holmes will start 2005 with a series of race in britain holmes will make her first track appearance on home soil since winning double olympic gold in january s norwich union international in glasgow she will also run in the grand prix in birmingham in february and may defend her indoor aaa 800m title in sheffield earlier that month i am still competitive and still want to win she said i m an athlete and i can t wait to get back on the track she added these event are also a great opportunity to thank the british public for the enormous level of support they have given me from the moment i stepped off that plane from greece the glasgow meeting will see holmes compete over 1500m in a five way match against sweden france russia and italy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC76KPos7_9w"
      },
      "source": [
        "### Using Google Universal Sentence Encoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2obo4x6c7nRD"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" \n",
        "model = hub.load(module_url)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u9Penun8M0l"
      },
      "source": [
        "def embed(input):\n",
        "  return model(input)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQDFO_S-twzW"
      },
      "source": [
        "def similarity_measure(input):\n",
        "  m_embed = embed(input)\n",
        "  distance = scipy.spatial.distance.cdist([m_embed[0]],[m_embed[1]],\"cosine\")[0] # first element\n",
        "  return (1-distance)  # (1 - cosine distance) gives cosine similarity"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z7gl978tjo4",
        "outputId": "307df981-12b4-41c8-d1d6-647b4b73d7cd"
      },
      "source": [
        "# test for dup one\n",
        "sentence = \"holmes starts 2005 gb events kelly holmes start 2005 series races britain holmes make first track appearancehome soil since winning double olympic gold january norwich union international glasgow also run grand prix birmingham february may defend indoor aaa 800m title sheffield earlier month still competitive still want win said athlete wait get back track added events also great opportunity thank british public enormous levels support given moment stepped plane greece glasgow meeting see holmes compete 1500m fiveway match sweden france russia italy\"\n",
        "message_embeddings = embed([sentence])\n",
        "message_embeddings.shape  #  The sentences get converted to a 512-dimensional vector."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQlSOta6t6er"
      },
      "source": [
        "input = []\n",
        "input.append(sim.text1[3403])\n",
        "input.append(sim.text2[3403])\n",
        "s_em = similarity_measure(input)[0]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkJlPhu_t-HX",
        "outputId": "fad563bb-5672-4caa-c891-6d001a7fda7a"
      },
      "source": [
        "s_em"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.999999999999964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPwPtqaYuAu0"
      },
      "source": [
        "# For given data\n",
        "\n",
        "sim_score = []\n",
        "for i in range(len(sim)):\n",
        "  input = []\n",
        "  input.append(sim.text1[i])\n",
        "  input.append(sim.text2[i])\n",
        "  s_em = similarity_measure(input)[0]\n",
        "  sim_score.append(s_em)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGEQTKuGuHxw",
        "outputId": "f397c2b0-29c7-448a-d34e-fd1ce8bc9bc8"
      },
      "source": [
        "len(sim_score)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4kJkJlwY97"
      },
      "source": [
        "sim['sim_score'] = sim_score"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Hu2cUkKUwcJY",
        "outputId": "f8d3a408-a443-4da8-cffb-8799fb39f141"
      },
      "source": [
        "sim.loc[sim['sim_score']>= 0.8]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>text1</th>\n",
              "      <th>text2</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>284</td>\n",
              "      <td>brown call for £5 5bn aid fund gordon brown ha...</td>\n",
              "      <td>brown to outline presidency goal next year wil...</td>\n",
              "      <td>0.855064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2284</th>\n",
              "      <td>2284</td>\n",
              "      <td>dvd copy protection strengthened dvd will be h...</td>\n",
              "      <td>dvd copy protection strengthened dvd will be h...</td>\n",
              "      <td>0.986489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2712</th>\n",
              "      <td>2712</td>\n",
              "      <td>learning to love broadband we are reaching the...</td>\n",
              "      <td>tv s future down the phone line internet tv ha...</td>\n",
              "      <td>0.811203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3013</th>\n",
              "      <td>3013</td>\n",
              "      <td>call for kenteris to be cleared kostas kenteri...</td>\n",
              "      <td>iaaf to rule on greek sprint pair greek sprint...</td>\n",
              "      <td>0.836589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3056</th>\n",
              "      <td>3056</td>\n",
              "      <td>howard dismisses tory tax fear michael howard ...</td>\n",
              "      <td>defection timed to hit tax pledge with impecca...</td>\n",
              "      <td>0.871753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3403</th>\n",
              "      <td>3403</td>\n",
              "      <td>holmes start 2005 with gb event kelly holmes w...</td>\n",
              "      <td>holmes start 2005 with gb event kelly holmes w...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3421</th>\n",
              "      <td>3421</td>\n",
              "      <td>blair dismisses quit claim report tony blair h...</td>\n",
              "      <td>fox attack blair s tory lie tony blair lied wh...</td>\n",
              "      <td>0.823750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3552</th>\n",
              "      <td>3552</td>\n",
              "      <td>hunt demo at labour meeting pro hunt supporter...</td>\n",
              "      <td>final hunt held a ban loom hunt in england and...</td>\n",
              "      <td>0.852930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3827</th>\n",
              "      <td>3827</td>\n",
              "      <td>newcastle 2 1 bolton kieron dyer smashed home ...</td>\n",
              "      <td>arsenal through on penalty arsenal win 4 2 on ...</td>\n",
              "      <td>0.806961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3859</th>\n",
              "      <td>3859</td>\n",
              "      <td>troubled marsh under sec scrutiny the u stock ...</td>\n",
              "      <td>marsh executive in guilty plea an executive at...</td>\n",
              "      <td>0.893727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unique_ID  ... sim_score\n",
              "284         284  ...  0.855064\n",
              "2284       2284  ...  0.986489\n",
              "2712       2712  ...  0.811203\n",
              "3013       3013  ...  0.836589\n",
              "3056       3056  ...  0.871753\n",
              "3403       3403  ...  1.000000\n",
              "3421       3421  ...  0.823750\n",
              "3552       3552  ...  0.852930\n",
              "3827       3827  ...  0.806961\n",
              "3859       3859  ...  0.893727\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GWGI_BqTwh7Z",
        "outputId": "4c0dc25f-db0d-4626-b447-f51a5932152e"
      },
      "source": [
        "submission = sim[[\"Unique_ID\",\"sim_score\"]]\n",
        "submission.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_ID</th>\n",
              "      <th>sim_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.416169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.251416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.513111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.355525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.638504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unique_ID  sim_score\n",
              "0          0   0.416169\n",
              "1          1   0.251416\n",
              "2          2   0.513111\n",
              "3          3   0.355525\n",
              "4          4   0.638504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ns_giEaqw-Z_",
        "outputId": "d8528a04-f9f1-4086-fa44-b959e79f1545"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "submission.to_csv(\"submission.csv\", encoding='utf-8', index=False)\n",
        "files.download('submission.csv')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f41b4883-8356-453a-8e18-dc43a4b93bf8\", \"submission.csv\", 96883)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jNhcD2HhUVd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}